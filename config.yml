#------------------------------Wandb Settings--------------------------------

use_wandb: true             # if true, use wandb for recording
project: StyleTransfer

# run info, sweep时会忽略
group: AODA
job_type: train

#------------------------------Base Options----------------------------------

isTrain: true               # true when training
checkpoints: ./checkpoints  # models are saved here
dataroot:                   # path to images (should have subfolders trainA, trainB, valA, valB, etc)
datarootA:                  # path to images A
datarootB:                  # path to images B
name: experiment_name       # name of the experiment. It decides where to store samples and models
model: aoda_gan             # chooses which model to use. [classifier | aoda_gan | test ]
n_classes: 0                # the number of labels for the dataset
direction: AtoB             # AtoB or BtoA
dataset_mode: unaligned     # chooses how datasets are loaded. [unaligned | aligned | single | colorization]
batch_size: 1               # input batch size
gpu_id: 0                   # 0 for GPU. -1 for CPU
input_nc: 3                 # num of input image channels: 3 for RGB and 1 for grayscale
output_nc: 3                # ditto
no_dropout: true            # no dropout for the generator
dropout: 0.0                # Dropout rate
serial_batches: false       # if true, takes images in order to make batches, otherwise takes them randomly
num_threads: 0              # num of threads for loading data, recommend windows 0, linux 4.
load_size: 286              # scale images to this size
crop_size: 256              # then crop to this size
preprocess: resize_and_crop # [resize_and_crop | crop | scale_width | scale_width_and_crop | none]
no_flip: false              # if true, do not flip the images for data augmentation
nz: 8                       # num of gen filters in first conv layer
ngf: 64                     # num of disc filters in the last conv layer
ndf: 64                     # num of disc filters in the first conv layer
ndisc_out_filters: 1        # num of disc filters in first conv layer
netD: basic                 # [basic | n_layers | pixel]. The basic model is a 70x70 PatchGAN.
netG: resnet_9blocks        # [resnet_9blocks_c |resnet_9blocks | resnet_6blocks | unet_256 | unet_128]
netGC: adaresnet_9blocks_c  # [resnet_9blocks_c | unet_256_c | adaresnet_9blocks_c]
n_layers_D: 3               # only used if netD==n_layers
norm: instance              # instance normalization or batch normalization [instance | batch | none]
init_type: normal           # network initialization [normal | xavier | kaiming | orthogonal]
init_gain: 0.02             # scaling factor for normal, xavier and orthogonal.
max_dataset_size: .inf      # Maximum number of samples allowed per dataset.
epoch: latest               # which epoch to load? set to latest to use latest cached model
load_iter: 0                # which iteration to load? if load_iter > 0, the code will load models by iter_[load_iter]; otherwise, the code will load models by [epoch]
verbose: false              # if true, print more debugging information

#------------------------------Train Options---------------------------------

beta1: 0.5                  # momentum term of adam
continue_train: false       # continue training: load the latest model
display_freq: 400           # frequency of showing training results on screen
epoch_count: 1              # the starting epoch count
gan_mode: lsgan             # [vanilla| lsgan | wgangp]. vanilla GAN loss is the cross-entropy objective 
identity: 0.5               # use identity mapping. Setting identity other than 1 has an effect of scaling the weight of the identity mapping loss.
lambda_A: 10.0              # weight for cycle loss (A -> B -> A)
lambda_B: 1.0               # weight for cycle loss (B -> A -> B)
lambda_C: 0.0               # weight for vgg loss
lambda_E: 0                 # weight for eta related loss
lambda_GAN: 1.0             # weight for GAN Loss
lambda_identity: 0          # use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the weight of the identity mapping loss.
lr: 0.0002                  # initial learning rate for adam
lr_g: 1e-4                  # initial learning rate for adam
lr_d: 4e-4                  # initial learning rate for adam
lr_policy: step             # learning rate policy. [linear | step | plateau | cosine]
lr_decay_iters: 50          # multiply by a gamma every lr_decay_iters iterations
mix_rec: false              # if to mix the recon as generation
n_epochs: 50                # number of epochs with the initial learning rate
n_epochs_decay: 150         # number of epochs to linearly decay learning rate to zero
niter: 400                  # number of iter at starting learning rate
niter_decay: 100            # number of iter to linearly decay learning rate to zero
no_ganFeat_loss: false      # if specified, do *not* use discriminator feature matching loss
no_html: false              # do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/
phase: train                # train
pool_size: 50               # the size of image buffer that stores previously generated images
pretrained_path: None       # specify the folder path to the pretrained weights
print_freq: 100             # frequency of showing training results on console
rand_p: 0.5                 # above this value, substitute
resume_state:               # resume training from the given state file "path/to/latest.state"
save_by_iter: false         # whether saves model by iteration
save_epoch_freq: 10         # frequency of saving checkpoints at the end of epochs
save_latest_freq: 5000      # frequency of saving the latest results

#-------------------------------End------------------------------------------